{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c5e0667",
   "metadata": {},
   "source": [
    "# Apple Health Intelligence System\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecc796a",
   "metadata": {},
   "source": [
    "## 1. Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1b0c2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['health_analyzer.py', 'health_analyzer.ipynb', 'README.md', '.git']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.listdir(\".\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "827e942a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def extract_health_data(xml_path='apple_health_export.xml'):\n",
    "    \"\"\"Parse Apple Health data directly from XML file\"\"\"\n",
    "    # Define comprehensive health metrics\n",
    "    HEALTH_METRICS = {\n",
    "        # Activity\n",
    "        \"HKQuantityTypeIdentifierStepCount\": \"steps\",\n",
    "        \"HKQuantityTypeIdentifierDistanceWalkingRunning\": \"distance\",\n",
    "        \"HKQuantityTypeIdentifierFlightsClimbed\": \"flights\",\n",
    "        \"HKQuantityTypeIdentifierActiveEnergyBurned\": \"active_cal\",\n",
    "        \"HKQuantityTypeIdentifierBasalEnergyBurned\": \"basal_cal\",\n",
    "        \"HKQuantityTypeIdentifierAppleExerciseTime\": \"exercise_min\",\n",
    "        \"HKQuantityTypeIdentifierVO2Max\": \"vo2_max\",\n",
    "        # Vitals\n",
    "        \"HKQuantityTypeIdentifierHeartRate\": \"heart_rate\",\n",
    "        \"HKQuantityTypeIdentifierRestingHeartRate\": \"resting_hr\",\n",
    "        \"HKQuantityTypeIdentifierWalkingHeartRateAverage\": \"walking_hr\",\n",
    "        \"HKQuantityTypeIdentifierBloodPressureSystolic\": \"bp_systolic\",\n",
    "        \"HKQuantityTypeIdentifierBloodPressureDiastolic\": \"bp_diastolic\",\n",
    "        \"HKQuantityTypeIdentifierBloodOxygenSaturation\": \"spo2\",\n",
    "        \"HKQuantityTypeIdentifierBodyTemperature\": \"body_temp\",\n",
    "        \"HKQuantityTypeIdentifierRespiratoryRate\": \"resp_rate\",\n",
    "        \"HKQuantityTypeIdentifierHeartRateVariabilitySDNN\": \"hrv\",\n",
    "        # Body\n",
    "        \"HKQuantityTypeIdentifierBodyMass\": \"weight\",\n",
    "        \"HKQuantityTypeIdentifierBodyFatPercentage\": \"body_fat\",\n",
    "        \"HKQuantityTypeIdentifierLeanBodyMass\": \"lean_mass\",\n",
    "        \"HKQuantityTypeIdentifierBodyMassIndex\": \"bmi\",\n",
    "        \"HKQuantityTypeIdentifierHeight\": \"height\",\n",
    "        # Sleep\n",
    "        \"HKCategoryTypeIdentifierSleepAnalysis\": \"sleep\",\n",
    "        # Nutrition\n",
    "        \"HKQuantityTypeIdentifierDietaryEnergyConsumed\": \"calories_consumed\",\n",
    "        \"HKQuantityTypeIdentifierDietaryCarbohydrates\": \"carbs\",\n",
    "        \"HKQuantityTypeIdentifierDietaryProtein\": \"protein\",\n",
    "        \"HKQuantityTypeIdentifierDietaryFatTotal\": \"fat\",\n",
    "        # Mindfulness\n",
    "        \"HKCategoryTypeIdentifierMindfulSession\": \"mindfulness\",\n",
    "        # Reproductive\n",
    "        \"HKCategoryTypeIdentifierOvulationTestResult\": \"ovulation_test\",\n",
    "        \"HKCategoryTypeIdentifierMenstrualFlow\": \"menstrual_flow\",\n",
    "    }\n",
    "\n",
    "    print(\n",
    "        f\"â³ Parsing XML file: {xml_path} (this may take several minutes for large files)\"\n",
    "    )\n",
    "\n",
    "    # Parse XML data directly\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    records = []\n",
    "    for i, record in enumerate(root.findall(\"Record\")):\n",
    "        if i % 10000 == 0:  # Print progress periodically\n",
    "            print(f\"ğŸ“Š Processed {i} records...\")\n",
    "\n",
    "        record_type = record.get(\"type\")\n",
    "        if record_type not in HEALTH_METRICS:\n",
    "            continue\n",
    "\n",
    "        # Get value and handle special cases\n",
    "        value = record.get(\"value\")\n",
    "        if not value:\n",
    "            continue\n",
    "\n",
    "        # Calculate duration-based metrics\n",
    "        if record_type == \"HKCategoryTypeIdentifierSleepAnalysis\":\n",
    "            start = pd.to_datetime(record.get(\"startDate\"))\n",
    "            end = pd.to_datetime(record.get(\"endDate\"))\n",
    "            value = (end - start).total_seconds() / 3600  # hours\n",
    "        elif record_type == \"HKCategoryTypeIdentifierMindfulSession\":\n",
    "            start = pd.to_datetime(record.get(\"startDate\"))\n",
    "            end = pd.to_datetime(record.get(\"endDate\"))\n",
    "            value = (end - start).total_seconds() / 60  # minutes\n",
    "\n",
    "        records.append(\n",
    "            {\n",
    "                \"type\": HEALTH_METRICS[record_type],\n",
    "                \"date\": pd.to_datetime(record.get(\"startDate\")).normalize(),\n",
    "                \"value\": float(value),\n",
    "                \"unit\": record.get(\"unit\", \"\"),\n",
    "                \"source\": record.get(\"sourceName\", \"\"),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    print(f\"âœ… Parsing complete! Total records: {len(records)}\")\n",
    "    return pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cb08fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â³ Parsing XML file: apple_health_export.xml (this may take several minutes for large files)\n",
      "ğŸ“Š Processed 0 records...\n",
      "ğŸ“Š Processed 10000 records...\n",
      "ğŸ“Š Processed 20000 records...\n",
      "ğŸ“Š Processed 30000 records...\n",
      "ğŸ“Š Processed 40000 records...\n",
      "ğŸ“Š Processed 50000 records...\n",
      "ğŸ“Š Processed 60000 records...\n",
      "ğŸ“Š Processed 70000 records...\n",
      "ğŸ“Š Processed 80000 records...\n",
      "ğŸ“Š Processed 90000 records...\n",
      "ğŸ“Š Processed 100000 records...\n",
      "ğŸ“Š Processed 110000 records...\n",
      "ğŸ“Š Processed 120000 records...\n",
      "ğŸ“Š Processed 130000 records...\n",
      "ğŸ“Š Processed 140000 records...\n",
      "ğŸ“Š Processed 150000 records...\n",
      "ğŸ“Š Processed 160000 records...\n",
      "ğŸ“Š Processed 170000 records...\n",
      "ğŸ“Š Processed 180000 records...\n",
      "ğŸ“Š Processed 190000 records...\n",
      "ğŸ“Š Processed 200000 records...\n",
      "ğŸ“Š Processed 210000 records...\n",
      "ğŸ“Š Processed 220000 records...\n",
      "ğŸ“Š Processed 230000 records...\n",
      "ğŸ“Š Processed 240000 records...\n",
      "ğŸ“Š Processed 250000 records...\n",
      "ğŸ“Š Processed 260000 records...\n",
      "ğŸ“Š Processed 270000 records...\n",
      "ğŸ“Š Processed 280000 records...\n",
      "ğŸ“Š Processed 290000 records...\n",
      "ğŸ“Š Processed 300000 records...\n",
      "ğŸ“Š Processed 310000 records...\n",
      "ğŸ“Š Processed 320000 records...\n",
      "ğŸ“Š Processed 330000 records...\n",
      "ğŸ“Š Processed 340000 records...\n",
      "ğŸ“Š Processed 350000 records...\n",
      "ğŸ“Š Processed 360000 records...\n",
      "ğŸ“Š Processed 370000 records...\n",
      "ğŸ“Š Processed 380000 records...\n",
      "ğŸ“Š Processed 390000 records...\n",
      "ğŸ“Š Processed 400000 records...\n",
      "ğŸ“Š Processed 410000 records...\n",
      "ğŸ“Š Processed 420000 records...\n",
      "ğŸ“Š Processed 430000 records...\n",
      "ğŸ“Š Processed 440000 records...\n",
      "ğŸ“Š Processed 450000 records...\n",
      "ğŸ“Š Processed 460000 records...\n",
      "ğŸ“Š Processed 470000 records...\n",
      "ğŸ“Š Processed 480000 records...\n",
      "ğŸ“Š Processed 490000 records...\n",
      "ğŸ“Š Processed 500000 records...\n",
      "ğŸ“Š Processed 510000 records...\n",
      "ğŸ“Š Processed 520000 records...\n",
      "ğŸ“Š Processed 530000 records...\n",
      "ğŸ“Š Processed 540000 records...\n",
      "ğŸ“Š Processed 550000 records...\n",
      "ğŸ“Š Processed 560000 records...\n",
      "ğŸ“Š Processed 570000 records...\n",
      "ğŸ“Š Processed 580000 records...\n",
      "ğŸ“Š Processed 590000 records...\n",
      "ğŸ“Š Processed 600000 records...\n",
      "ğŸ“Š Processed 610000 records...\n",
      "ğŸ“Š Processed 620000 records...\n",
      "ğŸ“Š Processed 630000 records...\n",
      "ğŸ“Š Processed 640000 records...\n",
      "ğŸ“Š Processed 650000 records...\n",
      "ğŸ“Š Processed 660000 records...\n",
      "ğŸ“Š Processed 670000 records...\n",
      "ğŸ“Š Processed 680000 records...\n",
      "ğŸ“Š Processed 690000 records...\n",
      "ğŸ“Š Processed 700000 records...\n",
      "ğŸ“Š Processed 710000 records...\n",
      "ğŸ“Š Processed 720000 records...\n",
      "ğŸ“Š Processed 730000 records...\n",
      "ğŸ“Š Processed 740000 records...\n",
      "ğŸ“Š Processed 750000 records...\n",
      "ğŸ“Š Processed 760000 records...\n",
      "ğŸ“Š Processed 770000 records...\n",
      "ğŸ“Š Processed 780000 records...\n",
      "ğŸ“Š Processed 790000 records...\n",
      "ğŸ“Š Processed 800000 records...\n",
      "ğŸ“Š Processed 810000 records...\n",
      "ğŸ“Š Processed 820000 records...\n",
      "ğŸ“Š Processed 830000 records...\n",
      "ğŸ“Š Processed 840000 records...\n",
      "ğŸ“Š Processed 850000 records...\n",
      "ğŸ“Š Processed 860000 records...\n",
      "ğŸ“Š Processed 870000 records...\n",
      "ğŸ“Š Processed 880000 records...\n",
      "ğŸ“Š Processed 890000 records...\n",
      "ğŸ“Š Processed 900000 records...\n",
      "ğŸ“Š Processed 910000 records...\n",
      "ğŸ“Š Processed 920000 records...\n",
      "ğŸ“Š Processed 930000 records...\n",
      "ğŸ“Š Processed 940000 records...\n",
      "ğŸ“Š Processed 950000 records...\n",
      "ğŸ“Š Processed 960000 records...\n",
      "ğŸ“Š Processed 970000 records...\n",
      "ğŸ“Š Processed 980000 records...\n",
      "ğŸ“Š Processed 990000 records...\n",
      "ğŸ“Š Processed 1000000 records...\n",
      "ğŸ“Š Processed 1010000 records...\n",
      "ğŸ“Š Processed 1020000 records...\n",
      "ğŸ“Š Processed 1030000 records...\n",
      "ğŸ“Š Processed 1040000 records...\n",
      "ğŸ“Š Processed 1050000 records...\n",
      "ğŸ“Š Processed 1060000 records...\n",
      "ğŸ“Š Processed 1070000 records...\n",
      "ğŸ“Š Processed 1080000 records...\n",
      "ğŸ“Š Processed 1090000 records...\n",
      "ğŸ“Š Processed 1100000 records...\n",
      "ğŸ“Š Processed 1110000 records...\n",
      "ğŸ“Š Processed 1120000 records...\n",
      "ğŸ“Š Processed 1130000 records...\n",
      "ğŸ“Š Processed 1140000 records...\n",
      "ğŸ“Š Processed 1150000 records...\n",
      "ğŸ“Š Processed 1160000 records...\n",
      "ğŸ“Š Processed 1170000 records...\n",
      "ğŸ“Š Processed 1180000 records...\n",
      "ğŸ“Š Processed 1190000 records...\n",
      "ğŸ“Š Processed 1200000 records...\n",
      "ğŸ“Š Processed 1210000 records...\n",
      "ğŸ“Š Processed 1220000 records...\n",
      "ğŸ“Š Processed 1230000 records...\n",
      "ğŸ“Š Processed 1240000 records...\n",
      "ğŸ“Š Processed 1250000 records...\n",
      "ğŸ“Š Processed 1260000 records...\n",
      "ğŸ“Š Processed 1270000 records...\n",
      "ğŸ“Š Processed 1280000 records...\n",
      "ğŸ“Š Processed 1290000 records...\n",
      "ğŸ“Š Processed 1300000 records...\n",
      "ğŸ“Š Processed 1310000 records...\n",
      "ğŸ“Š Processed 1320000 records...\n",
      "ğŸ“Š Processed 1330000 records...\n",
      "ğŸ“Š Processed 1340000 records...\n",
      "ğŸ“Š Processed 1350000 records...\n",
      "ğŸ“Š Processed 1360000 records...\n",
      "ğŸ“Š Processed 1370000 records...\n",
      "ğŸ“Š Processed 1380000 records...\n",
      "ğŸ“Š Processed 1390000 records...\n",
      "ğŸ“Š Processed 1400000 records...\n",
      "ğŸ“Š Processed 1410000 records...\n",
      "ğŸ“Š Processed 1420000 records...\n",
      "ğŸ“Š Processed 1430000 records...\n",
      "ğŸ“Š Processed 1440000 records...\n",
      "ğŸ“Š Processed 1450000 records...\n",
      "ğŸ“Š Processed 1460000 records...\n",
      "ğŸ“Š Processed 1470000 records...\n",
      "ğŸ“Š Processed 1480000 records...\n",
      "ğŸ“Š Processed 1490000 records...\n",
      "ğŸ“Š Processed 1500000 records...\n",
      "ğŸ“Š Processed 1510000 records...\n",
      "ğŸ“Š Processed 1520000 records...\n",
      "ğŸ“Š Processed 1530000 records...\n",
      "ğŸ“Š Processed 1540000 records...\n",
      "ğŸ“Š Processed 1550000 records...\n",
      "ğŸ“Š Processed 1560000 records...\n",
      "ğŸ“Š Processed 1570000 records...\n",
      "ğŸ“Š Processed 1580000 records...\n",
      "ğŸ“Š Processed 1590000 records...\n",
      "ğŸ“Š Processed 1600000 records...\n",
      "ğŸ“Š Processed 1610000 records...\n",
      "ğŸ“Š Processed 1620000 records...\n",
      "ğŸ“Š Processed 1630000 records...\n",
      "ğŸ“Š Processed 1640000 records...\n",
      "ğŸ“Š Processed 1650000 records...\n",
      "ğŸ“Š Processed 1660000 records...\n",
      "ğŸ“Š Processed 1670000 records...\n",
      "ğŸ“Š Processed 1680000 records...\n",
      "ğŸ“Š Processed 1690000 records...\n",
      "ğŸ“Š Processed 1700000 records...\n",
      "ğŸ“Š Processed 1710000 records...\n",
      "ğŸ“Š Processed 1720000 records...\n",
      "ğŸ“Š Processed 1730000 records...\n",
      "ğŸ“Š Processed 1740000 records...\n",
      "ğŸ“Š Processed 1750000 records...\n",
      "ğŸ“Š Processed 1760000 records...\n",
      "ğŸ“Š Processed 1770000 records...\n",
      "ğŸ“Š Processed 1780000 records...\n",
      "ğŸ“Š Processed 1790000 records...\n",
      "ğŸ“Š Processed 1800000 records...\n",
      "ğŸ“Š Processed 1810000 records...\n",
      "ğŸ“Š Processed 1820000 records...\n",
      "ğŸ“Š Processed 1830000 records...\n",
      "ğŸ“Š Processed 1840000 records...\n",
      "ğŸ“Š Processed 1850000 records...\n",
      "ğŸ“Š Processed 1860000 records...\n",
      "ğŸ“Š Processed 1870000 records...\n",
      "ğŸ“Š Processed 1880000 records...\n",
      "ğŸ“Š Processed 1890000 records...\n",
      "ğŸ“Š Processed 1900000 records...\n",
      "ğŸ“Š Processed 1910000 records...\n",
      "ğŸ“Š Processed 1920000 records...\n",
      "ğŸ“Š Processed 1930000 records...\n",
      "ğŸ“Š Processed 1940000 records...\n",
      "ğŸ“Š Processed 1950000 records...\n",
      "ğŸ“Š Processed 1960000 records...\n",
      "ğŸ“Š Processed 1970000 records...\n",
      "ğŸ“Š Processed 1980000 records...\n",
      "ğŸ“Š Processed 1990000 records...\n",
      "ğŸ“Š Processed 2000000 records...\n",
      "ğŸ“Š Processed 2010000 records...\n",
      "ğŸ“Š Processed 2020000 records...\n",
      "ğŸ“Š Processed 2030000 records...\n",
      "ğŸ“Š Processed 2040000 records...\n",
      "ğŸ“Š Processed 2050000 records...\n",
      "ğŸ“Š Processed 2060000 records...\n",
      "ğŸ“Š Processed 2070000 records...\n",
      "ğŸ“Š Processed 2080000 records...\n",
      "ğŸ“Š Processed 2090000 records...\n",
      "ğŸ“Š Processed 2100000 records...\n",
      "ğŸ“Š Processed 2110000 records...\n",
      "ğŸ“Š Processed 2120000 records...\n",
      "ğŸ“Š Processed 2130000 records...\n",
      "ğŸ“Š Processed 2140000 records...\n",
      "ğŸ“Š Processed 2150000 records...\n",
      "ğŸ“Š Processed 2160000 records...\n",
      "ğŸ“Š Processed 2170000 records...\n",
      "ğŸ“Š Processed 2180000 records...\n",
      "ğŸ“Š Processed 2190000 records...\n",
      "ğŸ“Š Processed 2200000 records...\n",
      "ğŸ“Š Processed 2210000 records...\n",
      "ğŸ“Š Processed 2220000 records...\n",
      "ğŸ“Š Processed 2230000 records...\n",
      "ğŸ“Š Processed 2240000 records...\n",
      "ğŸ“Š Processed 2250000 records...\n",
      "ğŸ“Š Processed 2260000 records...\n",
      "ğŸ“Š Processed 2270000 records...\n",
      "ğŸ“Š Processed 2280000 records...\n",
      "ğŸ“Š Processed 2290000 records...\n",
      "ğŸ“Š Processed 2300000 records...\n",
      "ğŸ“Š Processed 2310000 records...\n",
      "ğŸ“Š Processed 2320000 records...\n",
      "ğŸ“Š Processed 2330000 records...\n",
      "ğŸ“Š Processed 2340000 records...\n",
      "ğŸ“Š Processed 2350000 records...\n",
      "ğŸ“Š Processed 2360000 records...\n",
      "ğŸ“Š Processed 2370000 records...\n",
      "ğŸ“Š Processed 2380000 records...\n",
      "ğŸ“Š Processed 2390000 records...\n",
      "âœ… Parsing complete! Total records: 1991304\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>date</th>\n",
       "      <th>value</th>\n",
       "      <th>unit</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>height</td>\n",
       "      <td>2021-04-11 00:00:00+02:00</td>\n",
       "      <td>192.0</td>\n",
       "      <td>cm</td>\n",
       "      <td>Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>weight</td>\n",
       "      <td>2021-04-11 00:00:00+02:00</td>\n",
       "      <td>73.0</td>\n",
       "      <td>kg</td>\n",
       "      <td>JPâ€™s iPhone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>weight</td>\n",
       "      <td>2019-10-14 00:00:00+02:00</td>\n",
       "      <td>83.0</td>\n",
       "      <td>kg</td>\n",
       "      <td>Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>weight</td>\n",
       "      <td>2019-02-08 00:00:00+02:00</td>\n",
       "      <td>73.5</td>\n",
       "      <td>kg</td>\n",
       "      <td>Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weight</td>\n",
       "      <td>2023-11-19 00:00:00+02:00</td>\n",
       "      <td>80.0</td>\n",
       "      <td>kg</td>\n",
       "      <td>JPâ€™s iPhone 16 Pro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     type                      date  value unit              source\n",
       "0  height 2021-04-11 00:00:00+02:00  192.0   cm              Health\n",
       "1  weight 2021-04-11 00:00:00+02:00   73.0   kg         JPâ€™s iPhone\n",
       "2  weight 2019-10-14 00:00:00+02:00   83.0   kg              Health\n",
       "3  weight 2019-02-08 00:00:00+02:00   73.5   kg              Health\n",
       "4  weight 2023-11-19 00:00:00+02:00   80.0   kg  JPâ€™s iPhone 16 Pro"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [Cell 2] Execute extraction\n",
    "health_df = extract_health_data()\n",
    "health_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29595ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_health_data(df):\n",
    "    daily = df.pivot_table(index=\"date\", columns=\"type\", values=\"value\", aggfunc=\"sum\")\n",
    "\n",
    "    avg_cols = [\n",
    "        \"heart_rate\",\n",
    "        \"resting_hr\",\n",
    "        \"walking_hr\",\n",
    "        \"bp_systolic\",\n",
    "        \"bp_diastolic\",\n",
    "        \"spo2\",\n",
    "        \"body_temp\",\n",
    "        \"resp_rate\",\n",
    "        \"hrv\",\n",
    "        \"vo2_max\",\n",
    "    ]\n",
    "    last_cols = [\"weight\", \"body_fat\", \"lean_mass\", \"bmi\", \"height\"]\n",
    "\n",
    "    imputer = KNNImputer(n_neighbors=7)\n",
    "    daily_imputed = pd.DataFrame(\n",
    "        imputer.fit_transform(daily), columns=daily.columns, index=daily.index\n",
    "    )\n",
    "\n",
    "    if \"weight\" in daily_imputed and \"height\" in daily_imputed:\n",
    "        daily_imputed[\"bmi\"] = (\n",
    "            daily_imputed[\"weight\"] / (daily_imputed[\"height\"] / 100) ** 2\n",
    "        )\n",
    "\n",
    "    if \"active_cal\" in daily_imputed and \"basal_cal\" in daily_imputed:\n",
    "        daily_imputed[\"total_cal\"] = (\n",
    "            daily_imputed[\"active_cal\"] + daily_imputed[\"basal_cal\"]\n",
    "        )\n",
    "\n",
    "    daily_imputed[\"health_index\"] = (\n",
    "        0.15 * daily_imputed[\"steps\"].clip(upper=10000) / 10000\n",
    "        + 0.15 * daily_imputed[\"sleep\"].clip(lower=4, upper=10) / 8\n",
    "        + 0.10 * (1 - (daily_imputed[\"resting_hr\"] - 60) / 40)\n",
    "        + 0.10 * daily_imputed[\"vo2_max\"] / 60\n",
    "        + 0.10 * daily_imputed[\"mindfulness\"].clip(upper=60) / 60\n",
    "        + 0.10 * daily_imputed[\"spo2\"] / 100\n",
    "        + 0.10 * (daily_imputed[\"weight\"] / daily_imputed[\"weight\"].quantile(0.8))\n",
    "        + 0.20 * (1 - daily_imputed[\"hrv\"].clip(upper=200) / 200)\n",
    "    )\n",
    "\n",
    "    return daily_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c7be14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_health_models(daily):\n",
    "    \"\"\"Builds forecasting, prediction, anomaly detection, and clustering models from daily health data\"\"\"\n",
    "    models = {}\n",
    "\n",
    "    # Prophet model for step forecasting\n",
    "    steps_df = (\n",
    "        daily[[\"steps\"]]\n",
    "        .dropna()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"date\": \"ds\", \"steps\": \"y\"})\n",
    "    )\n",
    "    steps_model = Prophet(\n",
    "        seasonality_mode=\"multiplicative\",\n",
    "        yearly_seasonality=True,\n",
    "        weekly_seasonality=True,\n",
    "    )\n",
    "    steps_model.fit(steps_df)\n",
    "    models[\"steps_model\"] = steps_model\n",
    "\n",
    "    # LSTM model for health index prediction\n",
    "    if \"health_index\" in daily.columns:\n",
    "        target = \"health_index\"\n",
    "        features = [\"steps\", \"sleep\", \"resting_hr\", \"spo2\", \"hrv\"]\n",
    "        data = daily[features + [target]].dropna()\n",
    "\n",
    "        # Scale\n",
    "        scaler = StandardScaler()\n",
    "        scaled = scaler.fit_transform(data)\n",
    "\n",
    "        # Create sequences\n",
    "        def create_sequences(data, n_steps=14):\n",
    "            X, y = [], []\n",
    "            for i in range(len(data) - n_steps):\n",
    "                X.append(data[i : i + n_steps, :-1])\n",
    "                y.append(data[i + n_steps, -1])\n",
    "            return np.array(X), np.array(y)\n",
    "\n",
    "        X, y = create_sequences(scaled)\n",
    "\n",
    "        model = Sequential(\n",
    "            [\n",
    "                LSTM(64, activation=\"relu\", input_shape=(X.shape[1], X.shape[2])),\n",
    "                Dropout(0.3),\n",
    "                Dense(32, activation=\"relu\"),\n",
    "                Dense(1),\n",
    "            ]\n",
    "        )\n",
    "        model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "        model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            epochs=50,\n",
    "            batch_size=32,\n",
    "            verbose=0,\n",
    "            callbacks=[EarlyStopping(patience=5)],\n",
    "        )\n",
    "\n",
    "        models[\"health_index_model\"] = {\n",
    "            \"model\": model,\n",
    "            \"scaler\": scaler,\n",
    "            \"features\": features,\n",
    "        }\n",
    "\n",
    "    # Anomaly Detection\n",
    "    iso = IsolationForest(contamination=0.05, random_state=42)\n",
    "    daily[\"anomaly\"] = iso.fit_predict(daily.fillna(daily.median()))\n",
    "\n",
    "    # PCA for clustering\n",
    "    pca = PCA(n_components=3)\n",
    "    pca_components = pca.fit_transform(\n",
    "        StandardScaler().fit_transform(daily.fillna(daily.median()))\n",
    "    )\n",
    "    daily[[\"pca1\", \"pca2\", \"pca3\"]] = pca_components\n",
    "\n",
    "    return models, daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762c67d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model building process\n",
    "health_models, enhanced_daily = create_health_models(daily_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c457684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_health_dashboard(daily, models):\n",
    "    fig1 = go.Figure(\n",
    "        go.Scatter(\n",
    "            x=daily.index,\n",
    "            y=daily[\"health_index\"],\n",
    "            name=\"Health Index\",\n",
    "            line=dict(color=\"green\", width=3),\n",
    "        )\n",
    "    )\n",
    "    fig1.update_layout(title=\"Health Index Over Time\", template=\"plotly_dark\")\n",
    "\n",
    "    fig2 = px.imshow(\n",
    "        daily.corr(),\n",
    "        text_auto=\".2f\",\n",
    "        title=\"Metric Correlation Heatmap\",\n",
    "        color_continuous_scale=\"RdBu_r\",\n",
    "    )\n",
    "\n",
    "    fig3 = px.scatter_3d(\n",
    "        daily,\n",
    "        x=\"pca1\",\n",
    "        y=\"pca2\",\n",
    "        z=\"pca3\",\n",
    "        color=\"health_index\",\n",
    "        size=\"steps\",\n",
    "        hover_name=daily.index.strftime(\"%Y-%m-%d\"),\n",
    "        title=\"Health Clustering\",\n",
    "        color_continuous_scale=\"Viridis\",\n",
    "    )\n",
    "\n",
    "    future = models[\"steps_model\"].make_future_dataframe(periods=30)\n",
    "    forecast = models[\"steps_model\"].predict(future)\n",
    "    fig4 = go.Figure(\n",
    "        [\n",
    "            go.Scatter(x=forecast[\"ds\"], y=forecast[\"yhat\"], name=\"Forecast\"),\n",
    "            go.Scatter(x=daily.index, y=daily[\"steps\"], name=\"Actual\", mode=\"markers\"),\n",
    "        ]\n",
    "    )\n",
    "    fig4.update_layout(title=\"30-Day Step Forecast\", template=\"plotly_dark\")\n",
    "\n",
    "    dashboard = make_subplots(\n",
    "        rows=2,\n",
    "        cols=2,\n",
    "        specs=[\n",
    "            [{\"type\": \"xy\"}, {\"type\": \"heatmap\"}],\n",
    "            [{\"type\": \"scatter3d\"}, {\"type\": \"xy\"}],\n",
    "        ],\n",
    "        subplot_titles=[\n",
    "            \"Health Index\",\n",
    "            \"Correlations\",\n",
    "            \"PCA Clusters\",\n",
    "            \"Step Forecast\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    dashboard.add_trace(fig1.data[0], row=1, col=1)\n",
    "    dashboard.add_trace(fig2.data[0], row=1, col=2)\n",
    "    dashboard.add_trace(fig3.data[0], row=2, col=1)\n",
    "    for trace in fig4.data:\n",
    "        dashboard.add_trace(trace, row=2, col=2)\n",
    "\n",
    "    dashboard.update_layout(\n",
    "        height=900, title=\"ğŸ“ˆ Health Intelligence Dashboard\", showlegend=False\n",
    "    )\n",
    "    return dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72042619",
   "metadata": {},
   "outputs": [],
   "source": [
    "dashboard = create_health_dashboard(enhanced_daily, health_models)\n",
    "dashboard.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eeeaa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_daily.to_csv(\"health_analytics.csv\")\n",
    "dashboard.write_html(\"health_dashboard.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
