{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c5e0667",
   "metadata": {},
   "source": [
    "# Apple Health Intelligence System\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecc796a",
   "metadata": {},
   "source": [
    "## 1. Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1b0c2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['health_analyzer.py', 'health_analyzer.ipynb', 'README.md', '.git']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.listdir(\".\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "827e942a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def extract_health_data(xml_path='apple_health_export.xml'):\n",
    "    \"\"\"Parse Apple Health data directly from XML file\"\"\"\n",
    "    # Define comprehensive health metrics\n",
    "    HEALTH_METRICS = {\n",
    "        # Activity\n",
    "        \"HKQuantityTypeIdentifierStepCount\": \"steps\",\n",
    "        \"HKQuantityTypeIdentifierDistanceWalkingRunning\": \"distance\",\n",
    "        \"HKQuantityTypeIdentifierFlightsClimbed\": \"flights\",\n",
    "        \"HKQuantityTypeIdentifierActiveEnergyBurned\": \"active_cal\",\n",
    "        \"HKQuantityTypeIdentifierBasalEnergyBurned\": \"basal_cal\",\n",
    "        \"HKQuantityTypeIdentifierAppleExerciseTime\": \"exercise_min\",\n",
    "        \"HKQuantityTypeIdentifierVO2Max\": \"vo2_max\",\n",
    "        # Vitals\n",
    "        \"HKQuantityTypeIdentifierHeartRate\": \"heart_rate\",\n",
    "        \"HKQuantityTypeIdentifierRestingHeartRate\": \"resting_hr\",\n",
    "        \"HKQuantityTypeIdentifierWalkingHeartRateAverage\": \"walking_hr\",\n",
    "        \"HKQuantityTypeIdentifierBloodPressureSystolic\": \"bp_systolic\",\n",
    "        \"HKQuantityTypeIdentifierBloodPressureDiastolic\": \"bp_diastolic\",\n",
    "        \"HKQuantityTypeIdentifierBloodOxygenSaturation\": \"spo2\",\n",
    "        \"HKQuantityTypeIdentifierBodyTemperature\": \"body_temp\",\n",
    "        \"HKQuantityTypeIdentifierRespiratoryRate\": \"resp_rate\",\n",
    "        \"HKQuantityTypeIdentifierHeartRateVariabilitySDNN\": \"hrv\",\n",
    "        # Body\n",
    "        \"HKQuantityTypeIdentifierBodyMass\": \"weight\",\n",
    "        \"HKQuantityTypeIdentifierBodyFatPercentage\": \"body_fat\",\n",
    "        \"HKQuantityTypeIdentifierLeanBodyMass\": \"lean_mass\",\n",
    "        \"HKQuantityTypeIdentifierBodyMassIndex\": \"bmi\",\n",
    "        \"HKQuantityTypeIdentifierHeight\": \"height\",\n",
    "        # Sleep\n",
    "        \"HKCategoryTypeIdentifierSleepAnalysis\": \"sleep\",\n",
    "        # Nutrition\n",
    "        \"HKQuantityTypeIdentifierDietaryEnergyConsumed\": \"calories_consumed\",\n",
    "        \"HKQuantityTypeIdentifierDietaryCarbohydrates\": \"carbs\",\n",
    "        \"HKQuantityTypeIdentifierDietaryProtein\": \"protein\",\n",
    "        \"HKQuantityTypeIdentifierDietaryFatTotal\": \"fat\",\n",
    "        # Mindfulness\n",
    "        \"HKCategoryTypeIdentifierMindfulSession\": \"mindfulness\",\n",
    "        # Reproductive\n",
    "        \"HKCategoryTypeIdentifierOvulationTestResult\": \"ovulation_test\",\n",
    "        \"HKCategoryTypeIdentifierMenstrualFlow\": \"menstrual_flow\",\n",
    "    }\n",
    "\n",
    "    print(\n",
    "        f\"⏳ Parsing XML file: {xml_path} (this may take several minutes for large files)\"\n",
    "    )\n",
    "\n",
    "    # Parse XML data directly\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    records = []\n",
    "    for i, record in enumerate(root.findall(\"Record\")):\n",
    "        if i % 10000 == 0:  # Print progress periodically\n",
    "            print(f\"📊 Processed {i} records...\")\n",
    "\n",
    "        record_type = record.get(\"type\")\n",
    "        if record_type not in HEALTH_METRICS:\n",
    "            continue\n",
    "\n",
    "        # Get value and handle special cases\n",
    "        value = record.get(\"value\")\n",
    "        if not value:\n",
    "            continue\n",
    "\n",
    "        # Calculate duration-based metrics\n",
    "        if record_type == \"HKCategoryTypeIdentifierSleepAnalysis\":\n",
    "            start = pd.to_datetime(record.get(\"startDate\"))\n",
    "            end = pd.to_datetime(record.get(\"endDate\"))\n",
    "            value = (end - start).total_seconds() / 3600  # hours\n",
    "        elif record_type == \"HKCategoryTypeIdentifierMindfulSession\":\n",
    "            start = pd.to_datetime(record.get(\"startDate\"))\n",
    "            end = pd.to_datetime(record.get(\"endDate\"))\n",
    "            value = (end - start).total_seconds() / 60  # minutes\n",
    "\n",
    "        records.append(\n",
    "            {\n",
    "                \"type\": HEALTH_METRICS[record_type],\n",
    "                \"date\": pd.to_datetime(record.get(\"startDate\")).normalize(),\n",
    "                \"value\": float(value),\n",
    "                \"unit\": record.get(\"unit\", \"\"),\n",
    "                \"source\": record.get(\"sourceName\", \"\"),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    print(f\"✅ Parsing complete! Total records: {len(records)}\")\n",
    "    return pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cb08fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Parsing XML file: apple_health_export.xml (this may take several minutes for large files)\n",
      "📊 Processed 0 records...\n",
      "📊 Processed 10000 records...\n",
      "📊 Processed 20000 records...\n",
      "📊 Processed 30000 records...\n",
      "📊 Processed 40000 records...\n",
      "📊 Processed 50000 records...\n",
      "📊 Processed 60000 records...\n",
      "📊 Processed 70000 records...\n",
      "📊 Processed 80000 records...\n",
      "📊 Processed 90000 records...\n",
      "📊 Processed 100000 records...\n",
      "📊 Processed 110000 records...\n",
      "📊 Processed 120000 records...\n",
      "📊 Processed 130000 records...\n",
      "📊 Processed 140000 records...\n",
      "📊 Processed 150000 records...\n",
      "📊 Processed 160000 records...\n",
      "📊 Processed 170000 records...\n",
      "📊 Processed 180000 records...\n",
      "📊 Processed 190000 records...\n",
      "📊 Processed 200000 records...\n",
      "📊 Processed 210000 records...\n",
      "📊 Processed 220000 records...\n",
      "📊 Processed 230000 records...\n",
      "📊 Processed 240000 records...\n",
      "📊 Processed 250000 records...\n",
      "📊 Processed 260000 records...\n",
      "📊 Processed 270000 records...\n",
      "📊 Processed 280000 records...\n",
      "📊 Processed 290000 records...\n",
      "📊 Processed 300000 records...\n",
      "📊 Processed 310000 records...\n",
      "📊 Processed 320000 records...\n",
      "📊 Processed 330000 records...\n",
      "📊 Processed 340000 records...\n",
      "📊 Processed 350000 records...\n",
      "📊 Processed 360000 records...\n",
      "📊 Processed 370000 records...\n",
      "📊 Processed 380000 records...\n",
      "📊 Processed 390000 records...\n",
      "📊 Processed 400000 records...\n",
      "📊 Processed 410000 records...\n",
      "📊 Processed 420000 records...\n",
      "📊 Processed 430000 records...\n",
      "📊 Processed 440000 records...\n",
      "📊 Processed 450000 records...\n",
      "📊 Processed 460000 records...\n",
      "📊 Processed 470000 records...\n",
      "📊 Processed 480000 records...\n",
      "📊 Processed 490000 records...\n",
      "📊 Processed 500000 records...\n",
      "📊 Processed 510000 records...\n",
      "📊 Processed 520000 records...\n",
      "📊 Processed 530000 records...\n",
      "📊 Processed 540000 records...\n",
      "📊 Processed 550000 records...\n",
      "📊 Processed 560000 records...\n",
      "📊 Processed 570000 records...\n",
      "📊 Processed 580000 records...\n",
      "📊 Processed 590000 records...\n",
      "📊 Processed 600000 records...\n",
      "📊 Processed 610000 records...\n",
      "📊 Processed 620000 records...\n",
      "📊 Processed 630000 records...\n",
      "📊 Processed 640000 records...\n",
      "📊 Processed 650000 records...\n",
      "📊 Processed 660000 records...\n",
      "📊 Processed 670000 records...\n",
      "📊 Processed 680000 records...\n",
      "📊 Processed 690000 records...\n",
      "📊 Processed 700000 records...\n",
      "📊 Processed 710000 records...\n",
      "📊 Processed 720000 records...\n",
      "📊 Processed 730000 records...\n",
      "📊 Processed 740000 records...\n",
      "📊 Processed 750000 records...\n",
      "📊 Processed 760000 records...\n",
      "📊 Processed 770000 records...\n",
      "📊 Processed 780000 records...\n",
      "📊 Processed 790000 records...\n",
      "📊 Processed 800000 records...\n",
      "📊 Processed 810000 records...\n",
      "📊 Processed 820000 records...\n",
      "📊 Processed 830000 records...\n",
      "📊 Processed 840000 records...\n",
      "📊 Processed 850000 records...\n",
      "📊 Processed 860000 records...\n",
      "📊 Processed 870000 records...\n",
      "📊 Processed 880000 records...\n",
      "📊 Processed 890000 records...\n",
      "📊 Processed 900000 records...\n",
      "📊 Processed 910000 records...\n",
      "📊 Processed 920000 records...\n",
      "📊 Processed 930000 records...\n",
      "📊 Processed 940000 records...\n",
      "📊 Processed 950000 records...\n",
      "📊 Processed 960000 records...\n",
      "📊 Processed 970000 records...\n",
      "📊 Processed 980000 records...\n",
      "📊 Processed 990000 records...\n",
      "📊 Processed 1000000 records...\n",
      "📊 Processed 1010000 records...\n",
      "📊 Processed 1020000 records...\n",
      "📊 Processed 1030000 records...\n",
      "📊 Processed 1040000 records...\n",
      "📊 Processed 1050000 records...\n",
      "📊 Processed 1060000 records...\n",
      "📊 Processed 1070000 records...\n",
      "📊 Processed 1080000 records...\n",
      "📊 Processed 1090000 records...\n",
      "📊 Processed 1100000 records...\n",
      "📊 Processed 1110000 records...\n",
      "📊 Processed 1120000 records...\n",
      "📊 Processed 1130000 records...\n",
      "📊 Processed 1140000 records...\n",
      "📊 Processed 1150000 records...\n",
      "📊 Processed 1160000 records...\n",
      "📊 Processed 1170000 records...\n",
      "📊 Processed 1180000 records...\n",
      "📊 Processed 1190000 records...\n",
      "📊 Processed 1200000 records...\n",
      "📊 Processed 1210000 records...\n",
      "📊 Processed 1220000 records...\n",
      "📊 Processed 1230000 records...\n",
      "📊 Processed 1240000 records...\n",
      "📊 Processed 1250000 records...\n",
      "📊 Processed 1260000 records...\n",
      "📊 Processed 1270000 records...\n",
      "📊 Processed 1280000 records...\n",
      "📊 Processed 1290000 records...\n",
      "📊 Processed 1300000 records...\n",
      "📊 Processed 1310000 records...\n",
      "📊 Processed 1320000 records...\n",
      "📊 Processed 1330000 records...\n",
      "📊 Processed 1340000 records...\n",
      "📊 Processed 1350000 records...\n",
      "📊 Processed 1360000 records...\n",
      "📊 Processed 1370000 records...\n",
      "📊 Processed 1380000 records...\n",
      "📊 Processed 1390000 records...\n",
      "📊 Processed 1400000 records...\n",
      "📊 Processed 1410000 records...\n",
      "📊 Processed 1420000 records...\n",
      "📊 Processed 1430000 records...\n",
      "📊 Processed 1440000 records...\n",
      "📊 Processed 1450000 records...\n",
      "📊 Processed 1460000 records...\n",
      "📊 Processed 1470000 records...\n",
      "📊 Processed 1480000 records...\n",
      "📊 Processed 1490000 records...\n",
      "📊 Processed 1500000 records...\n",
      "📊 Processed 1510000 records...\n",
      "📊 Processed 1520000 records...\n",
      "📊 Processed 1530000 records...\n",
      "📊 Processed 1540000 records...\n",
      "📊 Processed 1550000 records...\n",
      "📊 Processed 1560000 records...\n",
      "📊 Processed 1570000 records...\n",
      "📊 Processed 1580000 records...\n",
      "📊 Processed 1590000 records...\n",
      "📊 Processed 1600000 records...\n",
      "📊 Processed 1610000 records...\n",
      "📊 Processed 1620000 records...\n",
      "📊 Processed 1630000 records...\n",
      "📊 Processed 1640000 records...\n",
      "📊 Processed 1650000 records...\n",
      "📊 Processed 1660000 records...\n",
      "📊 Processed 1670000 records...\n",
      "📊 Processed 1680000 records...\n",
      "📊 Processed 1690000 records...\n",
      "📊 Processed 1700000 records...\n",
      "📊 Processed 1710000 records...\n",
      "📊 Processed 1720000 records...\n",
      "📊 Processed 1730000 records...\n",
      "📊 Processed 1740000 records...\n",
      "📊 Processed 1750000 records...\n",
      "📊 Processed 1760000 records...\n",
      "📊 Processed 1770000 records...\n",
      "📊 Processed 1780000 records...\n",
      "📊 Processed 1790000 records...\n",
      "📊 Processed 1800000 records...\n",
      "📊 Processed 1810000 records...\n",
      "📊 Processed 1820000 records...\n",
      "📊 Processed 1830000 records...\n",
      "📊 Processed 1840000 records...\n",
      "📊 Processed 1850000 records...\n",
      "📊 Processed 1860000 records...\n",
      "📊 Processed 1870000 records...\n",
      "📊 Processed 1880000 records...\n",
      "📊 Processed 1890000 records...\n",
      "📊 Processed 1900000 records...\n",
      "📊 Processed 1910000 records...\n",
      "📊 Processed 1920000 records...\n",
      "📊 Processed 1930000 records...\n",
      "📊 Processed 1940000 records...\n",
      "📊 Processed 1950000 records...\n",
      "📊 Processed 1960000 records...\n",
      "📊 Processed 1970000 records...\n",
      "📊 Processed 1980000 records...\n",
      "📊 Processed 1990000 records...\n",
      "📊 Processed 2000000 records...\n",
      "📊 Processed 2010000 records...\n",
      "📊 Processed 2020000 records...\n",
      "📊 Processed 2030000 records...\n",
      "📊 Processed 2040000 records...\n",
      "📊 Processed 2050000 records...\n",
      "📊 Processed 2060000 records...\n",
      "📊 Processed 2070000 records...\n",
      "📊 Processed 2080000 records...\n",
      "📊 Processed 2090000 records...\n",
      "📊 Processed 2100000 records...\n",
      "📊 Processed 2110000 records...\n",
      "📊 Processed 2120000 records...\n",
      "📊 Processed 2130000 records...\n",
      "📊 Processed 2140000 records...\n",
      "📊 Processed 2150000 records...\n",
      "📊 Processed 2160000 records...\n",
      "📊 Processed 2170000 records...\n",
      "📊 Processed 2180000 records...\n",
      "📊 Processed 2190000 records...\n",
      "📊 Processed 2200000 records...\n",
      "📊 Processed 2210000 records...\n",
      "📊 Processed 2220000 records...\n",
      "📊 Processed 2230000 records...\n",
      "📊 Processed 2240000 records...\n",
      "📊 Processed 2250000 records...\n",
      "📊 Processed 2260000 records...\n",
      "📊 Processed 2270000 records...\n",
      "📊 Processed 2280000 records...\n",
      "📊 Processed 2290000 records...\n",
      "📊 Processed 2300000 records...\n",
      "📊 Processed 2310000 records...\n",
      "📊 Processed 2320000 records...\n",
      "📊 Processed 2330000 records...\n",
      "📊 Processed 2340000 records...\n",
      "📊 Processed 2350000 records...\n",
      "📊 Processed 2360000 records...\n",
      "📊 Processed 2370000 records...\n",
      "📊 Processed 2380000 records...\n",
      "📊 Processed 2390000 records...\n",
      "✅ Parsing complete! Total records: 1991304\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>date</th>\n",
       "      <th>value</th>\n",
       "      <th>unit</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>height</td>\n",
       "      <td>2021-04-11 00:00:00+02:00</td>\n",
       "      <td>192.0</td>\n",
       "      <td>cm</td>\n",
       "      <td>Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>weight</td>\n",
       "      <td>2021-04-11 00:00:00+02:00</td>\n",
       "      <td>73.0</td>\n",
       "      <td>kg</td>\n",
       "      <td>JP’s iPhone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>weight</td>\n",
       "      <td>2019-10-14 00:00:00+02:00</td>\n",
       "      <td>83.0</td>\n",
       "      <td>kg</td>\n",
       "      <td>Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>weight</td>\n",
       "      <td>2019-02-08 00:00:00+02:00</td>\n",
       "      <td>73.5</td>\n",
       "      <td>kg</td>\n",
       "      <td>Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weight</td>\n",
       "      <td>2023-11-19 00:00:00+02:00</td>\n",
       "      <td>80.0</td>\n",
       "      <td>kg</td>\n",
       "      <td>JP’s iPhone 16 Pro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     type                      date  value unit              source\n",
       "0  height 2021-04-11 00:00:00+02:00  192.0   cm              Health\n",
       "1  weight 2021-04-11 00:00:00+02:00   73.0   kg         JP’s iPhone\n",
       "2  weight 2019-10-14 00:00:00+02:00   83.0   kg              Health\n",
       "3  weight 2019-02-08 00:00:00+02:00   73.5   kg              Health\n",
       "4  weight 2023-11-19 00:00:00+02:00   80.0   kg  JP’s iPhone 16 Pro"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [Cell 2] Execute extraction\n",
    "health_df = extract_health_data()\n",
    "health_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29595ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_health_data(df):\n",
    "    daily = df.pivot_table(index=\"date\", columns=\"type\", values=\"value\", aggfunc=\"sum\")\n",
    "\n",
    "    avg_cols = [\n",
    "        \"heart_rate\",\n",
    "        \"resting_hr\",\n",
    "        \"walking_hr\",\n",
    "        \"bp_systolic\",\n",
    "        \"bp_diastolic\",\n",
    "        \"spo2\",\n",
    "        \"body_temp\",\n",
    "        \"resp_rate\",\n",
    "        \"hrv\",\n",
    "        \"vo2_max\",\n",
    "    ]\n",
    "    last_cols = [\"weight\", \"body_fat\", \"lean_mass\", \"bmi\", \"height\"]\n",
    "\n",
    "    imputer = KNNImputer(n_neighbors=7)\n",
    "    daily_imputed = pd.DataFrame(\n",
    "        imputer.fit_transform(daily), columns=daily.columns, index=daily.index\n",
    "    )\n",
    "\n",
    "    if \"weight\" in daily_imputed and \"height\" in daily_imputed:\n",
    "        daily_imputed[\"bmi\"] = (\n",
    "            daily_imputed[\"weight\"] / (daily_imputed[\"height\"] / 100) ** 2\n",
    "        )\n",
    "\n",
    "    if \"active_cal\" in daily_imputed and \"basal_cal\" in daily_imputed:\n",
    "        daily_imputed[\"total_cal\"] = (\n",
    "            daily_imputed[\"active_cal\"] + daily_imputed[\"basal_cal\"]\n",
    "        )\n",
    "\n",
    "    daily_imputed[\"health_index\"] = (\n",
    "        0.15 * daily_imputed[\"steps\"].clip(upper=10000) / 10000\n",
    "        + 0.15 * daily_imputed[\"sleep\"].clip(lower=4, upper=10) / 8\n",
    "        + 0.10 * (1 - (daily_imputed[\"resting_hr\"] - 60) / 40)\n",
    "        + 0.10 * daily_imputed[\"vo2_max\"] / 60\n",
    "        + 0.10 * daily_imputed[\"mindfulness\"].clip(upper=60) / 60\n",
    "        + 0.10 * daily_imputed[\"spo2\"] / 100\n",
    "        + 0.10 * (daily_imputed[\"weight\"] / daily_imputed[\"weight\"].quantile(0.8))\n",
    "        + 0.20 * (1 - daily_imputed[\"hrv\"].clip(upper=200) / 200)\n",
    "    )\n",
    "\n",
    "    return daily_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c7be14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_health_models(daily):\n",
    "    \"\"\"Builds forecasting, prediction, anomaly detection, and clustering models from daily health data\"\"\"\n",
    "    models = {}\n",
    "\n",
    "    # Prophet model for step forecasting\n",
    "    steps_df = (\n",
    "        daily[[\"steps\"]]\n",
    "        .dropna()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"date\": \"ds\", \"steps\": \"y\"})\n",
    "    )\n",
    "    steps_model = Prophet(\n",
    "        seasonality_mode=\"multiplicative\",\n",
    "        yearly_seasonality=True,\n",
    "        weekly_seasonality=True,\n",
    "    )\n",
    "    steps_model.fit(steps_df)\n",
    "    models[\"steps_model\"] = steps_model\n",
    "\n",
    "    # LSTM model for health index prediction\n",
    "    if \"health_index\" in daily.columns:\n",
    "        target = \"health_index\"\n",
    "        features = [\"steps\", \"sleep\", \"resting_hr\", \"spo2\", \"hrv\"]\n",
    "        data = daily[features + [target]].dropna()\n",
    "\n",
    "        # Scale\n",
    "        scaler = StandardScaler()\n",
    "        scaled = scaler.fit_transform(data)\n",
    "\n",
    "        # Create sequences\n",
    "        def create_sequences(data, n_steps=14):\n",
    "            X, y = [], []\n",
    "            for i in range(len(data) - n_steps):\n",
    "                X.append(data[i : i + n_steps, :-1])\n",
    "                y.append(data[i + n_steps, -1])\n",
    "            return np.array(X), np.array(y)\n",
    "\n",
    "        X, y = create_sequences(scaled)\n",
    "\n",
    "        model = Sequential(\n",
    "            [\n",
    "                LSTM(64, activation=\"relu\", input_shape=(X.shape[1], X.shape[2])),\n",
    "                Dropout(0.3),\n",
    "                Dense(32, activation=\"relu\"),\n",
    "                Dense(1),\n",
    "            ]\n",
    "        )\n",
    "        model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "        model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            epochs=50,\n",
    "            batch_size=32,\n",
    "            verbose=0,\n",
    "            callbacks=[EarlyStopping(patience=5)],\n",
    "        )\n",
    "\n",
    "        models[\"health_index_model\"] = {\n",
    "            \"model\": model,\n",
    "            \"scaler\": scaler,\n",
    "            \"features\": features,\n",
    "        }\n",
    "\n",
    "    # Anomaly Detection\n",
    "    iso = IsolationForest(contamination=0.05, random_state=42)\n",
    "    daily[\"anomaly\"] = iso.fit_predict(daily.fillna(daily.median()))\n",
    "\n",
    "    # PCA for clustering\n",
    "    pca = PCA(n_components=3)\n",
    "    pca_components = pca.fit_transform(\n",
    "        StandardScaler().fit_transform(daily.fillna(daily.median()))\n",
    "    )\n",
    "    daily[[\"pca1\", \"pca2\", \"pca3\"]] = pca_components\n",
    "\n",
    "    return models, daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762c67d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model building process\n",
    "health_models, enhanced_daily = create_health_models(daily_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c457684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_health_dashboard(daily, models):\n",
    "    fig1 = go.Figure(\n",
    "        go.Scatter(\n",
    "            x=daily.index,\n",
    "            y=daily[\"health_index\"],\n",
    "            name=\"Health Index\",\n",
    "            line=dict(color=\"green\", width=3),\n",
    "        )\n",
    "    )\n",
    "    fig1.update_layout(title=\"Health Index Over Time\", template=\"plotly_dark\")\n",
    "\n",
    "    fig2 = px.imshow(\n",
    "        daily.corr(),\n",
    "        text_auto=\".2f\",\n",
    "        title=\"Metric Correlation Heatmap\",\n",
    "        color_continuous_scale=\"RdBu_r\",\n",
    "    )\n",
    "\n",
    "    fig3 = px.scatter_3d(\n",
    "        daily,\n",
    "        x=\"pca1\",\n",
    "        y=\"pca2\",\n",
    "        z=\"pca3\",\n",
    "        color=\"health_index\",\n",
    "        size=\"steps\",\n",
    "        hover_name=daily.index.strftime(\"%Y-%m-%d\"),\n",
    "        title=\"Health Clustering\",\n",
    "        color_continuous_scale=\"Viridis\",\n",
    "    )\n",
    "\n",
    "    future = models[\"steps_model\"].make_future_dataframe(periods=30)\n",
    "    forecast = models[\"steps_model\"].predict(future)\n",
    "    fig4 = go.Figure(\n",
    "        [\n",
    "            go.Scatter(x=forecast[\"ds\"], y=forecast[\"yhat\"], name=\"Forecast\"),\n",
    "            go.Scatter(x=daily.index, y=daily[\"steps\"], name=\"Actual\", mode=\"markers\"),\n",
    "        ]\n",
    "    )\n",
    "    fig4.update_layout(title=\"30-Day Step Forecast\", template=\"plotly_dark\")\n",
    "\n",
    "    dashboard = make_subplots(\n",
    "        rows=2,\n",
    "        cols=2,\n",
    "        specs=[\n",
    "            [{\"type\": \"xy\"}, {\"type\": \"heatmap\"}],\n",
    "            [{\"type\": \"scatter3d\"}, {\"type\": \"xy\"}],\n",
    "        ],\n",
    "        subplot_titles=[\n",
    "            \"Health Index\",\n",
    "            \"Correlations\",\n",
    "            \"PCA Clusters\",\n",
    "            \"Step Forecast\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    dashboard.add_trace(fig1.data[0], row=1, col=1)\n",
    "    dashboard.add_trace(fig2.data[0], row=1, col=2)\n",
    "    dashboard.add_trace(fig3.data[0], row=2, col=1)\n",
    "    for trace in fig4.data:\n",
    "        dashboard.add_trace(trace, row=2, col=2)\n",
    "\n",
    "    dashboard.update_layout(\n",
    "        height=900, title=\"📈 Health Intelligence Dashboard\", showlegend=False\n",
    "    )\n",
    "    return dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72042619",
   "metadata": {},
   "outputs": [],
   "source": [
    "dashboard = create_health_dashboard(enhanced_daily, health_models)\n",
    "dashboard.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eeeaa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_daily.to_csv(\"health_analytics.csv\")\n",
    "dashboard.write_html(\"health_dashboard.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
